{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_to_md5.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMfDvegW0COAzNA8XNg0Mpu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQw_YxV_RdGq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How we can make encoded hash from data?"
      ],
      "metadata": {
        "id": "W1n5hLu5UNSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hash_out = hashlib.md5(\"Hello, World!\".encode())\n",
        "hash_out.hexdigest()"
      ],
      "metadata": {
        "id": "BvIy8bD3Rvbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normally, we cannot crack the hash codes(Get the real data from its hash). But, there are some sources you can find like : [crackstation](https://crackstation.net/)"
      ],
      "metadata": {
        "id": "UCkqbglsVGxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create two dict from valid outputs"
      ],
      "metadata": {
        "id": "Mn5jaIfCVwuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_l_to_index = {l:i for i,l in enumerate(\"0123456789abcdef\")}\n",
        "dict_i_to_l = {dict_l_to_index[i]:i for i in dict_l_to_index.keys()}"
      ],
      "metadata": {
        "id": "NLSRIPp3RudN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create random strings from ascii codes. Next, we are going to feed these data to out DNN model."
      ],
      "metadata": {
        "id": "inMK0rbUV9ZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = np.random.randint(97,122,(50000,10))"
      ],
      "metadata": {
        "id": "8MjOHHyXTNKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make the hash encoded outputs from input data."
      ],
      "metadata": {
        "id": "AfuuPDUIWnsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "for i in range(input1.shape[0]):\n",
        "  str1 = \"\".join(map(chr,input1[i]))\n",
        "  #print(str1)\n",
        "  md5 = hashlib.md5(str1.encode())\n",
        "  str_hex = md5.hexdigest()\n",
        "  #print(str_hex)\n",
        "  #print(len(list(map(ord,str_hex))))\n",
        "  output.append(str_hex)\n"
      ],
      "metadata": {
        "id": "ocwwvaZOYBOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataframe out of inputs"
      ],
      "metadata": {
        "id": "eGJtDYM5XJoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(input1,columns=[f\"_{i}\" for i in range(10)])\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "S6oeGQVkgXMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create target on datatframe"
      ],
      "metadata": {
        "id": "qecc934_Xf_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"target\"] = output"
      ],
      "metadata": {
        "id": "WyBQKGIWhaa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We can save the dataset..."
      ],
      "metadata": {
        "id": "d4npiwgTXqeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.to_parquet(\"input_to_md5.prq\")"
      ],
      "metadata": {
        "id": "n0HJ4w3vidc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a dataset for regression model"
      ],
      "metadata": {
        "id": "sLaG95ydYDte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class cls_data_regression(Dataset):\n",
        "  def __init__(self, df) -> None:\n",
        "      super().__init__()\n",
        "      self.dataset = df\n",
        "\n",
        "      print(\"Head of dataset: \", self.dataset.head(2))\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, index) :\n",
        "      lst_output = list(map(ord,self.dataset.loc[index,\"target\"]))\n",
        "      return torch.tensor(self.dataset.iloc[index, 0:10])/150.0, torch.tensor(lst_output)/1.0\n"
      ],
      "metadata": {
        "id": "8yvEshtGs7B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataset for classification "
      ],
      "metadata": {
        "id": "urVPzn12YQ2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class cls_data_classification(Dataset):\n",
        "  def __init__(self, df) -> None:\n",
        "      super().__init__()\n",
        "      self.dataset = df\n",
        "\n",
        "      print(\"Head of dataset: \", self.dataset.head(2))\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, index) :\n",
        "      \n",
        "      t_output = torch.zeros((32,16))\n",
        "      for i,l in enumerate(self.dataset.loc[index,\"target\"]):\n",
        "        t_output[i,dict_l_to_index[l]] = 1.0\n",
        "      t_output = t_output.reshape((-1,))\n",
        "      return torch.tensor(self.dataset.iloc[index, 0:10])/150.0, t_output\n"
      ],
      "metadata": {
        "id": "sVVJSzzOSASL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cls_model_lreg(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "      super().__init__()\n",
        "      self.model = nn.Sequential(\n",
        "          nn.Linear(10,512),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(512,1024),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(1024,64),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.2),\n",
        "          nn.Linear(64,32)\n",
        "      )     \n",
        "\n",
        "  def forward(self,x_train):\n",
        "\n",
        "    logits = self.model(x_train)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "K0e8hoDmuOrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cls_model_classification(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "      super().__init__()\n",
        "      self.model = nn.Sequential(\n",
        "          nn.Linear(10,2048),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(2048,1024),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.2),\n",
        "          nn.Linear(1024,512),\n",
        "                  \n",
        "      )\n",
        "\n",
        "      self.sigm = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x_train):\n",
        "\n",
        "    logits = self.sigm(self.model(x_train))\n",
        "    return logits"
      ],
      "metadata": {
        "id": "vpvFek06Vx1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_md5 = pd.read_parquet(\"input_to_md5.prq\")"
      ],
      "metadata": {
        "id": "HAodOkcYzGbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "dVXMrXb13u1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train , df_test = train_test_split(df1,test_size=.1)"
      ],
      "metadata": {
        "id": "seuWWEBx4nOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = cls_data_classification(df_train.reset_index().drop(columns=[\"index\"]))\n",
        "\n",
        "ds_test = cls_data_classification(df_test.reset_index().drop(columns=[\"index\"]))\n",
        "\n",
        "trainLoader = DataLoader(ds_train,batch_size=16)\n",
        "testLoader = DataLoader(ds_test,batch_size=16)\n"
      ],
      "metadata": {
        "id": "uH4ihYUW40-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f_train(net, trainLoader, valLoader, optim1, criterion1):\n",
        "  \n",
        "  for ep in range(2):\n",
        "    for it , (x,y) in enumerate(trainLoader):\n",
        "      optim1.zero_grad()\n",
        "      x,y = x.cuda(),y.cuda()\n",
        "      logits = net(x)\n",
        "\n",
        "      loss = criterion(logits,y)\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optim1.step()\n",
        "\n",
        "      if it%100 == 0:\n",
        "        print(\"Loss:\", loss)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x4OSw_KX98VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def f_evaluate(net, criterion, dataloader):\n",
        "    net.eval()\n",
        "\n",
        "    mean_acc, mean_loss = 0, 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x,y in dataloader:           \n",
        "            x,y = x.cuda(),y.cuda()\n",
        "            logits = net(x)\n",
        "            \n",
        "            #print(\"X:\",x)\n",
        "            print(\"y^:\", logits)\n",
        "            \n",
        "            \n",
        "            count += 1\n",
        "            \n",
        "        return logits\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "PqaQnVPxTIcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = cls_model_classification()\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.BCELoss()#nn.MSELoss()\n",
        "opti = Adam(net.parameters(),lr=6e-3)\n",
        "\n",
        "f_train(net,trainLoader,testLoader,opti,criterion)"
      ],
      "metadata": {
        "id": "J19w978B6C0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = f_evaluate(net,criterion,testLoader)"
      ],
      "metadata": {
        "id": "F5UazRyI74Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\".join(chr(i) for i in (ds_test[0][0]*150).int().tolist()))"
      ],
      "metadata": {
        "id": "6u0JUHAKsXBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UKdOe0yfauIM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}